2019，9.24：
#
	学习mysql的锁机制，总结提高查询效率的方式
	git合并冲突
	建一个maven项目
	安装HBASE
@
	*InnoDB引擎特点：支持事务，采用行级锁
	只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！ 
	
	*事务主要用来管理 insert,update,delete 语句
	
	*一个事务的结束标志是commit，当事务执行中断，回滚到保存点一般都要进行commit，该事务可以
	理解成原事务的"子事务"，保存点以前的数据操作得以保留，从而不用放弃原事务里的所有操作
	因此事务中的回滚跟事务的原子性不冲突。
	
锁机制：【两个事务不能同时操作一行数据】
	
	
	并发事务带来的问题【这些问题都是基于并发事务产生的，如果该引擎不支持并发事务，甚至不
						支持事务，就不会有这些问题，但事务的存在肯定是利大于弊，例如有了事务
						才能在，操作执行到一半，程序【java程序或其他语言程序】中断时，利用事务中的保存点
						回滚到中断之前数据的状态，发生中断操作之前的操作都是有效的
						】：
	
			【数据值不对叫脏读，数据被删叫不可重复读，数据条数变多叫幻读】

	
				更新丢失：多个事务都要更新同一个数据时，最后一个提交的事务所做的更新会覆盖
						  掉前面事务的更新
				
				脏读：一个事务正在对一条记录做修改，在这个事务并提交前，这条记录的数据就处于
					不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取
					了这些“脏”的数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。
					这种现象被形象地叫做“脏读”。
					
					【是怎么读到了未提交的更改？
					！！！虽然未提交但并不意味着没写到数据库文件中，其实只要将事务的隔离级别
					设置为 read uncommited,就能读到没有手动提交的事务里所更改的数据
					
					】
					
					
		
				不可重复读【语句级，针对的是同一个事务中的连续等价条件的select语句】：
							一个事务在读取某些数据已经发生了改变、或某些记录已经被删除了！
							这种现象叫做“不可重复读”。
							
							【默认的级别是可重复读，即当事务的隔离级别为可重复读时，在同一个事务
							  里连续读到的数据不变，即使两次select之间另外一个事务对同一条数据进行
							  了修改！因为对于同一个事务而言查到的数据是来自于内存，虽然数据库文件
							  改了，但一开始就加载了上个版本的数据库文件的内存没有改，所以同一个事务
							  中数据没变
							  
							  如果设置成read committed，那么在同一个事务中的第二次读到的数据就应来自更改
							  后的数据库文件，这样就读不到原来的数据了，【原来的数据在内存里】就会发生不可
							  重复读
							  
							  当然也有可能是新的数据库文件里的数据同步到了内存中，内存里的数据也得到了
							  更新，再读内存也读不到原来的数据了
							  】
							
				
				幻读【事务级，不同的事务才会发生这种现象】："不同事务"按相同的查询条件重新读取以前检索过的数据，
					 却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。
					 
					 这属于正常现象，而innoDB默认的事务隔离级别repeatable read ,就允许这种现象发生
					【这时重新读取的数据来自于数据库文件了，也有可能读到的是同步后的内存】
					 
				
		解决这些问题的方式：
		
					隔离事务：
							1.一种是在读取数据前，对其加锁，阻止其他事务对数据进行修改。
							  【说白了就是让事务真正的并发变成事务的串行，只不过此时串行
							   的事务之间执行时间间隔很短，用户看上去事务还是同时完成的一样】
							
							2.在某一个时间点对数据库生成一个数据快照，相当于数据的副本
							 相当于同一种数据的多个版本，称为数据多版本并发控制MVCC
							 
							 在MVCC中，读分为快照读，当前读
							 
							 快照读，不加任何锁；当前读，当前读返回的记录，都会加上排他锁
		
							mysql中 快照读：select; 当前读：insert/delete/update
															【增删改属于特殊读】
	
								即mysql默认已经给当前读加排他锁来避免出现并发事务所带来的问题
					
			隔离事务级别：未提交读，已提交读，可重复读，可序列化【级别递增】
							
	
	！select语句不会自动提交事务，增删改语句会自动提交事务【这里的自动提交跟手动commit不同，
	  除了表示一个事务的结束，还将操作会写到数据库文件上】若手动开启了事务start transaction;
	  此时增删改自带的提交事务的功能就只剩下操作数据库文件了，这时事务的结束标志是手动输入的
	  commit命令。
	  
	！！即默认情况下，一条增删改语句就表示一个事务，而select语句不是事务，也不归事务管理，但不影响
	  事务里有select语句
	  
	
	总结：read uncommitted;此时事务读的数据都是来自于数据库文件，读到了没有对方输入commit
		  但确实写进数据库文件的数据，就会发生脏读，不可重复读，和幻读
		  【只能保证不读取物理上损坏的数据，读取没有损坏的数据】
		  
		  
		  read committed;此时事务第二次读的数据也是来自于数据库文件，所以会发生不可重复读和
						 幻读			 
		  【对于同一个事务而言，该级别的数据一致性是语句级的，即同一个事务下，再执行一次
		    相同的语句，结果可以不同	】		

		
		  repeatable read;此时事务第二次读的数据是来自于之前加载过数据库文件的内存，这样就能读到
						  更改前的数据，即所谓读到重复的,应该会发生幻读，但实测并未发生
			【对于同一个事务而言，该级别的数据一致性是事务级的，即同一个事务下，再执行一次
		    相同的语句，结果一定相同，但下一个事务就不一定相同了】
	
	
		  serializable;事务序列化，即此时事务之间的关系就可以当成串行，而不是并发了，上述
					   问题都不会发生
			【最高级别，也是事务级，但这个事务级表示"同一个数据库"只能有一个事务在执行，事务
			 之间是串行，上一个事务没执行完，下一个事务的操作执行不了，当然这就与并发事务
			 真正矛盾了，一般不会选择这种级别来隔离事务】
			
		！！！总之，事务隔离级别配合commit【事务的结束标志】某种程度上决定了呈现给用户看的数据
			  是来自之前加载好数据的内存，还是来自直接或者间接的数据库文件【因为有可能数据库文件又
			  同步到了内存中，更新了内存值】，会话中不同的数据来源，就会产生不可重复读，脏读等
			  问题。
			
	
	【*Java中Savepoint类用来标记事务执行的过程，由连接对象调用setSavepoint("xxx");设置保存点
		配合连接对象的rollback("xxx"),commit()回滚到事务中断之前已经在当前会话/连接的内存中更
		新好的数据，通过commit()永久写到数据库文件中	
	  
	  *mysql中的select里的limit,oracle不支持
	  
	  *复制数据库中的表：1.CREATE TABLE targetTable LIKE sourceTable;复制该表的结构包括所用的引擎，约束等
						 2.INSERT INTO targetTable SELECT * FROM sourceTable;复制该表的数据
	  
	  *关于java连接数据库，有很多框架，jar包，如c3p0,DBUtils...是对jdbc和jdbc连接池的封装
	  
	  *apache DBUtils :
		commons-dbutils---apache的jdbc工具类库，简化了连接数据库的步骤
	  
	  *ComboPooledDataSource cpd = new ComboPooledDataSource("mysql");
	   Connection conn = cpd.getConnection(); 
	   QueryRunner qr = new QueryRunner();
	   String sql="xxx";
	   User user = qr.query(conn,sql,new BeanHandler<User>(User.class),...)//这样可以直接
	   将查询到的一条记录封装成对象，这里底层用到了反射，若用BeanListHandler，就能将结果集
	   封装成对象集
	   
	  *sql.properties由用户自己指定各种sql语句的key值，从而在更换不同关系型数据库时可以通过
	  更改相关key的value值，来适应不同的数据库，降低耦合
	  
	  *现在数据传输用的是json格式
	  
	  
	  】
	
	
怎样提高查询效率：
	
		1.减少查询次数
		2.优化select语句，减少表连接次数
		3.给经过复杂查询得到的结果建立视图
		4.适当给表建立索引
		5.大量数据均匀插入到多张表中
		
		
		
		
		
		
		
	